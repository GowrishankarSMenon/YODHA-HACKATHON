# MedScan AI - LLM-Based Extraction Backend

## Overview
LLM-powered medical document extraction pipeline that converts OCR text into structured JSON.

**Workflow:** `DOCUMENT â†’ OCR â†’ LLM â†’ DATABASE â†’ FETCH`

## Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run Server
```bash
cd backend
python main.py
```

Server starts at: `http://localhost:8000`

### 3. API Documentation
Interactive docs: `http://localhost:8000/docs`

## API Endpoints

### Process Document
**POST** `/api/process-document`

Upload PDF/image â†’ OCR â†’ LLM extraction â†’ Structured JSON

**Example Response:**
```json
{
  "record_id": "rec_98765",
  "patient_id": "HOSP-2025-001",
  "document_type": "OPD_NOTE",
  "extracted_data": {
    "diagnosis": "Type 2 Diabetes Mellitus",
    "blood_pressure": "130/90",
    "medications": [
      {"name": "Metformin", "dose": "500mg", "frequency": "BD"}
    ]
  },
  "confidence_score": 0.92,
  "status": "AUTO_APPROVED",
  "processed_at": "2026-01-09T10:32:40Z"
}
```

### Get All Records
**GET** `/api/records`

Returns all processed medical records.

### Get Single Record
**GET** `/api/records/{record_id}`

Fetch specific record by ID.

### Test LLM Extraction
**POST** `/api/test-llm`

Test LLM extraction with raw OCR text (no file upload).

## Document Types Supported

- **OPD_NOTE** - Out-patient department notes
- **LAB_REPORT** - Laboratory test results
- **PRESCRIPTION** - Medicine prescriptions
- **GENERAL** - Generic documents

## Auto-Approval Logic

| Confidence Score | Status |
|-----------------|--------|
| â‰¥ 0.90 | AUTO_APPROVED |
| 0.70 - 0.89 | PENDING_REVIEW |
| < 0.70 | REJECTED |

## Project Structure

```
backend/
â”œâ”€â”€ main.py                 # FastAPI app with LLM pipeline
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ llm_extractor.py   # LLM extraction service
â”‚   â”œâ”€â”€ ai_engine.py       # Existing mock AI (for reference)
â”‚   â”œâ”€â”€ sample_opd_ocr.txt # Sample OPD OCR output
â”‚   â””â”€â”€ sample_lab_ocr.txt # Sample lab report OCR
â”œâ”€â”€ models/
â”‚   â””â”€â”€ models.py          # Pydantic schemas
â”œâ”€â”€ database/
â”‚   â””â”€â”€ database.py        # In-memory storage
â””â”€â”€ requirements.txt
```

## Testing

### Using Swagger UI
1. Go to `http://localhost:8000/docs`
2. Try **POST /api/process-document**
3. Upload a test file (or use fallback with sample OCR text)
4. Check extracted JSON

### Using cURL
```bash
# Process a document
curl -X POST "http://localhost:8000/api/process-document" \
  -F "file=@sample_opd.pdf"

# Get all records
curl "http://localhost:8000/api/records"

# Get specific record
curl "http://localhost:8000/api/records/rec_12345"
```

## Key Features

âœ… Auto-detection of document type  
âœ… Intelligent field extraction (diagnosis, medications, vitals, etc.)  
âœ… Confidence scoring with auto-approval  
âœ… Support for nested data (medications array)  
âœ… Fallback OCR simulation for testing  
âœ… RESTful API design  

## Notes for Hackathon

- **OCR Integration**: Your teammate implements OCR in `ai_engine.py` / `ai_worker.py`
- **LLM Simulation**: Currently using regex/pattern matching (fast for hackathon)
- **Production**: Replace with real LLM API (OpenAI, Gemini) by updating `llm_extractor.py`
- **Database**: In-memory storage for demo (easily switch to MongoDB later)

## Next Steps

1. âœ… Basic LLM extraction working
2. ðŸ”„ Integrate real OCR from teammate
3. ðŸ”„ Add queue management for bulk processing
4. ðŸ”„ Frontend integration
5. ðŸ”„ Deploy to cloud
